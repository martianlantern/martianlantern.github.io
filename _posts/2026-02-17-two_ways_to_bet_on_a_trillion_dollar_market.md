---
layout: post
title: 2 ways to bet on a Trillion Dollar Market
date: 2026-02-17
comments: true
tags: [ai, business, strategy, anthropic, openai]
archive: false
---

I was listening to [Dario Amodei's interview with dwarkesh patel](https://www.youtube.com/results?search_query=dwarkesh+patel) and found his insights into how anthropic plans their capex investments and path to profitability quite fascinating. They need to balance their risks into how much compute to build for the next 2 years in advance based on current demands because the data centers take 2 years to build. If they overestimate their demand then they won't have enough profit in the next years and will go bankrupt while if they underestimate it they won't be able to match the demand and will risk losing their customers to their competitors, this is what he calls their cone of uncertainty. This sentiment felt weird to me because openai seems to aggressively bullish on their capex investments, infact sam altman disclosed they will be [spending $1 trillion on compute infra across microsoft, oracle, nvidia and coreweave between 2025 and 2035](https://tomtunguz.com/openai-hardware-spending-2025-2035/) while also [partnerring with cerebras](https://openai.com/index/cerebras-partnership/), so why do these 2 AI companies have completely different capex investment strategies?

The business model of anthropic relies on building things that enterprises will pay for and use that to build a path of profitability. As dario said anthropic has 10X it's revenue every year since 2023, but it can only continue for so long as the GDP is only finite and once majority of the value is catpured it will start showing diminishing returns, If growth slows down to 5X and not 10X and they purchased compute based 10X multiplier prediction they will go bankrupt. They are cautious of capex and only focusing on a few things and getting them right

Throughout our history whenever a technological revolution occurs it brings together an enormous value generation with it which can be measured in terms of productivity, GDP increase, increase in standard of living, etc. But dario mentions that AI hasn't fully diffused as it's effects are yet to be seen in economic growth<sup><a href="#fn1" id="ref1">1</a></sup>. This also means that there is a lot of value that is untouched and yet to be generated, openai seems to be in a strategy where they want to dominate the market and capture all this value. They seem to be like facebook in this sense, aggressively grow, capture the entire market and thus capture all the value that will be generated by the technology and a path of profitability will emerge later. This is pretty much consistent with their investments across every possible field where AI is yet to emerge
- They [wanted to acquire Windsurf for $3 billion](https://www.bloomberg.com/news/articles/2025-05-06/openai-reaches-agreement-to-buy-startup-windsurf-for-3-billion) to own the developer IDE stack (they got out competed by google at the last minute)
- They [acquired Neptune](https://openai.com/index/openai-to-acquire-neptune/) to strengthen their internal model training infrastructure
- They [merged with io Products](https://openai.com/sam-and-jony/) bringing Jony Ive into the fold to build hardware products
- They [launched Prism](https://openai.com/index/introducing-prism/), a colloborative and AI assisted latex editor
- They [introduced OpenAI for Healthcare](https://openai.com/index/openai-for-healthcare/)
- They [used GPT 5 to autonomously design cell synthesis recipies](https://openai.com/index/gpt-5-lowers-protein-synthesis-cost/) 
- They [built shopping research into ChatGPT](https://openai.com/index/chatgpt-shopping-research/)
- They [invested in building Human Brain Computer Interfaces](https://openai.com/index/investing-in-merge-labs/)
- and just this month they acqui hired<sup><a href="#fn2" id="ref2">2</a></sup>, [Peter Steinberger and OpenClaw](https://techcrunch.com/2026/02/15/openclaw-creator-peter-steinberger-joins-openai/) to drive the next generation of personal agents
- and many other things which I might (definitely) have missed

They are trying to have a hold of everything that AI will have impact on

Anthropic is trying to survive by focusing only on a few bets while openai needs at least some of their many bets to work to eventually get the payouts. I don't know which strategy will workout for either of them, but it would be surely fun to come back to this note after 5, 10, or 20 years and figure out how things eventually turned out for them. This brings me to another thing which I found fascinating from the interview which is the ["country of geniuses"](https://www.darioamodei.com/essay/the-adolescence-of-technology) and by dario's predictions will take 2 years in the best scenario and 10 years in the worst case. So if the combined market is going to be so enormous then ig it does not make sense which strategy you are using as long as you don't die, there will be enough value to capture for everyone

<img src="/assets/images/ai_summit/ai_summit.png" width="700" style="display: block; margin: 0 auto; width: 50%;">

---

<div class="footnotes">
<p id="fn1"><sup>1</sup> There is an argument to be made here as to why has this diffusion has been slow, infact it is quite fast compared to other technological revolutions, but it appears to be slow because the improvement in models capabilities are far exceeding than it's adoption can keep up. If you were an enterprise and someone used to do workflow x or y, you realize the models can now do it, but someone still has to program it to do it, provide the relevant context around it, handle the edge cases where someone else was correlated with workflow x and y via z, you update the context and it's harness and realize that the model is now smart enough to handle it on it's own but someone has to now test it, and yade yada the list goes on, and also don't forget by the time you did all this <a href="https://www.anthropic.com/news/claude-opus-4-6">Opus 4.6</a> dropped which can now one shot workflow x and y via z : ) <a href="#ref1">↩</a></p>

<p id="fn2"><sup>2</sup> Aqui hire is a relatively new term that was extensively used in 2025 (<a href="https://groq.com/newsroom/groq-and-nvidia-enter-non-exclusive-inference-technology-licensing-agreement-to-accelerate-ai-inference-at-global-scale">nvidia aqui hired groq</a>, <a href="https://www.forbes.com/sites/janakirammsv/2025/06/23/meta-invests-14-billion-in-scale-ai-to-strengthen-model-training/">Meta acqui hires Scale AI</a>, <a href="https://www.cnbc.com/2025/07/14/cognition-to-buy-ai-startup-windsurf-days-after-google-poached-ceo.html">Google acqui hired windsurf</a>), this happens when companies want to acquire a competitor but cannot go through the legal route because of anti trust lawsuits and DOJ, so instead they hire out all the founders, key people (and the domain expertise) who built the underlying technology stack and replicate in their business. The company is then left as a husk just to survive with it's employees unfair value returns on their stock options, again quite fascinating to read, <a href="https://en.wikipedia.org/wiki/Acqui-hiring">https://en.wikipedia.org/wiki/Acqui-hiring</a> <a href="#ref2">↩</a></p>
</div>
